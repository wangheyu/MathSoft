\documentclass{ctexbook}  
\usepackage{fontspec}
\usepackage{ctex}  
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{mathrsfs}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage[normalem]{ulem}  
\usepackage{subcaption}  
\usepackage{framed} 
\usepackage{enumitem} % 需要引入 enumitem 宏包
\usetikzlibrary{arrows,intersections}

%\setCJKmainfont{Source Han Serif SC} % 将主字体设为思源宋体，需要电脑安装此字体  
  
% \newenvironment{remark}  
%   {{\par\bf 注记: } \fangsong }  
%   {\par}

\newenvironment{Example}  
  {{\par\noindent\bf 例子: } \kaishu }  
  {\par}

\newfontfamily\yuanti{cwTeXYen} 

% 创建一个特定的定理样式和计数器  
\newtheorem{theorem}{定理}  
%\newtheorem{example}{例}

\newtheorem{definition}[theorem]{定义} % 定义 'definition' 环境    
% 创建其他定理样式并使用上述“theorem”的计数器  
\newtheorem{lemma}[theorem]{引理}  
\newtheorem{corollary}[theorem]{推论}  
\newtheorem{proposition}[theorem]{命题}  
%\newtheorem*{proposition}{命题}  
\newtheorem*{theorem*}{定理}  
\newtheorem{example}[theorem]{例}
\newtheorem{note}[theorem]{注记}
\newtheorem{challenge}[theorem]{挑战}  
\newtheorem{question}[theorem]{问题}  
\newtheorem{remark}[theorem]{备注}  

\numberwithin{theorem}{chapter}  
%\numberwithin{equation}{section} 
%\numberwithin{example}{section} 
%\numberwithin{definition}{section} 

%\numberwithin{figure}{section} 

\makeatletter  
%\@addtoreset{example}{section}  
\makeatother

\newcommand{\PP}{\mathbb{P}} 
\newcommand{\EE}{\mathbb{E}} 
\newcommand{\V}[1]{\mathbf{#1}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\SR}{\mathscr{R}}
\newcommand{\Sol}{\noindent {\bfseries 解}}

\title{数学软件}  
\author{Wang Heyu}  
\date{\today}  

\begin{document}  
\maketitle  

\chapter{环境设置}

数学家是最不依赖工具的群体之一。在人类文明史的大部分时期，数学家们只依靠纸笔和大脑来进行研究，如果说要有什么辅助神器，
那么也就是黑板和粉笔，最多把咖啡算上。以上这些设备和环境，至今仍然对数学家，哪怕是应用数学家也非常重要。这也是我们学院的咖啡这么优秀的原因之一。
但是随着计算机这个某种程度上说是数学家的工作成果之一，它的迅速发展，也开始成为数学家，特别是应用数学家的重要工具之一。这就是我们这个课程开设的原因。
本课程的主要目的是引导未来的数学家，也就是你们，获得一些计算机编程的基本技能，以及一些数学软件的使用技巧。这些技能和技巧，将会在你们的学习和研究中发挥重要作用。

但是时间到了 2022 年底，事情发生了进一步的变化。在那一年的 11 月，openai 公司发布了第一个 ``真正让人惊讶'' 的大预言模型：chat-GPT 3.5，从那以后，
大语言模型开始以前所未有的速度发展。到今天，我估计在座的每一位同学，都已经在某种程度上开始使用大语言模型，可能帮你收集学习资料，可能帮你写作业，写年终小结，
甚至写情书。

这一点同样也影响了数学的学习和研究。在这个技术出现的头几个月，大多数数学家都是抱着一种 ``这个东西不会对我有什么影响'' 的态度。但是很快，至少我自己就发现，
这个东西能极大提高我的工作效率。比如尽管我理论上可以直接阅读英语，但通过它我能够以阅读母语的速度阅读几乎任何外文文献。

\begin{example}
  我们来阅读 AI 的基础之一，随机梯度下降算法的开创性论文：
  Herbert Robbins \textup{\&} Sutton Monro 1951, A Stochastic Approximation Method\cite{robbins1951stochastic}。 

  \begin{enumerate}
    \item 通过大语言模型找到这篇关键论文。如果你问了正确的问题，比如：“请推荐随机梯度下降法的关键论文。” 
    一般大语言模型只能给出文献索引，你需要自己去找到这篇论文，比如我们的图书馆。当然你也可以问大模型：“哪里可以下载到这篇论文？” 
    但这样的问题一般不会得到太正面的回答。要学会结合使用已有的资源。
    \item 对待一篇论文的一般性态度是：我们有没有必要读，有没有必要精读？特别是我们在日常工作中，往往是根据关键字得到文献列表，
    如何筛选出我们真正需要的文献，是科研和学习的重要技能。一个简单的办法是在不下载原文的情况下，直接问大模型：“请给出这篇文章的主要内容。”
    这有助于我们做初步的筛选。
    \item 对于初步筛选的论文，我们可能需要做的选择是是否进一步精读。在这个阶段，我们应该已经获得了下载的原文。所以我们可以上传这篇论文，
    然后请求大模型做分析和总结。这里由于大模型理论上并不会记忆你上传的数据，所以通常情况下我们不用考虑泄密的问题。当然机密文件除外。
    一般比如说你尚未投稿的论文，通过这种和大模型对话的方式是不会泄露的。我们可以上传之后问大模型：“请分析这篇文章的主要内容和结论。”
    \item 尽管你已经上传了全部论文，但是你会发现不管你怎么提问，大模型只会做总结，而不会具体的一对一翻译。这里既有算法模型的原因，
    也有保护隐私的原因。但是如果你打算进一步精度一篇外文文献，那么逐词翻译是一个非常常见的理解过程。这里我们可以利用大模型的视觉模型，
    也就是把每一段论文的照片发给它，让它翻译。此时大模型会集中注意力于字面翻译，你也可以主动要求大模型尽量给出专业的翻译，不要评论，
    不要扩展讨论，如果有看不清的地方，用上下文推断，最后再以 latex 格式输出。这样你就能得到一个非常好的格式化翻译文本，以便精读。
  \end{enumerate}
\end{example}

到这里我们还可以说大模型只是做了一些文书工作。但是当具备深度学习的 GPT o1，
Deepseek R1，Qianwen qvq和 Kimi K1 等深度思考模型出现之后，甚至我们都可以和它们讨论专业数学问题了。就像我的一位同事根据亲身经历的反馈，
他把自己正在探索的开放问题提交给了深度思考模型，
模型仔细思考后给出了一大堆似是而非的结果，非常像一位没有准备的学生在考试中的表现。但是，其中它提出的一种证明，尽管一看就是错误的，
但提示了他两个看上去完全无关的理论之间的联系，
这给他了一个全新的方向性启示，然后按着这个思路走下去，他最后完成了这个工作。我自己也有类似的感受，和深度思考模型讨论，
非常想和一位基础扎实，但思维脱跳的学生讨论。
而且这个学生的推理能力提升极快，目前这几个月给我的感觉，已经超过了硕士生的平均水平[doge]

再比如它确实能够完善我的代码，
让我在写代码的时候更加专注于算法本身，而不是一些语法细节，同时它让我的代码具有完善的注释和文档，以及严谨的风格，优美的缩进等等。
当让它也能帮我快速地完成一些非常枯燥的文书工作，比如工作汇报，年度总结等等。最后，尽管我已经过了要写情书的年纪，但它确实能极大提升我的 email 和推荐信的书写质量，
特别是英语场合。可以说，目前在我的工作、学习和生活的很多场景，我都已经有意无意地大量使用大语言模型，这里也包括了我的专业工作。而且通过和我的同事的交流，
我发现这并不是我的个人感觉，事实上几乎我的所有同事，都已经在自己的研究工作中或多或少地使用这一重要工具，这远比我们当初预计的影响要大得多。特别是

所以几乎可以肯定地说，未来的数学家，哪怕是纯粹数学家，也很难不使用大语言模型来提升他的工作效率。所以从这个学期开始，我们进一步对我们的课程进行改革，
我们将更多地引入大语言模型相关的内容，并且在整个课程中，鼓励大家去主动使用大语言模型，来提升自己的学习和工作效率。所以我们先来设置或对齐一下我们的工作环境。

\section{大语言模型}
大语言模型（Large Language Model，LLM）是一种基于深度学习技术构建的人工智能模型，专门用于处理和生成自然语言文本。这个定义本身是 Kimi K1.5（深度思考版本）
在联网的情况下给出的。与此同时 Deepseek R1 的回答是：服务器繁忙，请稍后再试。这也是我推荐和个人使用最多的两个国产大语言模型。我个人的感觉是这两个模型都很好，
Qianwen 和 Kimi 更加偏文科生一些，能处理较长的文本，翻译和文书写作更好一些，同时 Kimi 的 K1 也有一定的推理能力；而 Deepseek R1 则很像经典印象的理科生，
有很强的逻辑推理能力，
文字表述方面偏简洁，但如果你给了很明确的指示，它也能做的很好。当然目前使用 Deepseek 的主要困难在于服务器反应不够及时，这也是我同时推荐 Qianwen/Kimi 的原因之一。
不管怎么说，这些模型都足够我们这门课程使用了。此外，这些模型都是免费的，强烈建议大家如果还没有账号，都去注册一个。

我们这里先简单地讨论一下大语言模型的本质，因为这有助于我们进一步合理使用它们。一个训练完毕的大语言模型，是一个具有极高维数（一般有大约 7000 亿个参数），
并带有复杂网络结构的知识图谱。它当中几乎覆盖了我们人类目前所有的知识，但它并不是一个经典意义上的数据库。尽管训练它时，人类输入了大量的文献，
但这些文献本身并不在这个知识图谱中，这个知识图谱中记录的只是人类在这些文献的引导下回答相关问题时组织对话的频率（我们不用概率，因为尽管参数量极大，
但毕竟还是有限个）所以从这个意义上说，它更像是“熟读唐诗三百首，不会作诗也会吟”。它将人类的知识库，抽象成一个超高维的流形曲面。这个曲面只存在在概率空间中，
我们不可能精确地绘制它，我们只是通过随机采样得到的参数去逼近它，这个过程被称为“训练”。等训练完成后，我们的全部随机参数就可以看作是这个人类知识曲面的一个逼近。
而推理过程，就是根据提问形成一个局部曲面片，然后用概率模型去寻找最一致的语言序列最为后续回答。因为整个推理过程也是随机的，因此即便相同的问题，我们也有可能得到不同的回答。

更深入的算法细节，我们在以后的专题再讨论。
而这里我们就先非常粗浅地说，大语言模型本质上是一个文科生。它对问题的回答内容，匹配的是人类文献中类似回答的频率，本质上它的思维能力仍然是有限的，
同时它并不会严格意义上的逻辑推理。这一点在早期的模型中表现的非常明显。它在回答简单的数学问题的时候，比如整数的加法，它都可能回答错误，
因为它只是以一个符合人类回答频率的方式随机给出一个答案。这也说明平均意义上的人类，事实上也并不是很擅长数学。
深度思考模型的出现其实就是为了解决这个问题。深度学习网络开始学习真正的人类逻辑推理，并用逻辑推理去检查大语言模型的输出内容是否有逻辑上的冲突。
目前这方面的突出成果就是大语言模型在数学问题上的表现越来越出色，比如我们问它一个有一定难度的微积分甚至数学分析的证明，它也有一定可能给出正确的答案。


\bibliography{mathsoft.bib}
\bibliographystyle{plain}


\end{document}  

